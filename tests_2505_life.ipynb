{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure both processes get same audio\n",
    "\n",
    "\n",
    "-choose file\n",
    "- process via diarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_and_process_connections_interval_sec: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61520/2240759009.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import timedelta\n",
    "from app.settings import settings\n",
    "from app.database_redis.connection import get_redis_client\n",
    "from app.services.audio.redis import Diarisation,Transcript\n",
    "from app.services.audio.redis import Connection, Diarizer, Meeting, Transcriber\n",
    "\n",
    "#list of common words that are strong glitch indicators that speech be removed from output\n",
    "glitches = ['DimaTorzok',' Tchau.']\n",
    "\n",
    "\n",
    "class DataPreparation:\n",
    "    @staticmethod\n",
    "    def prep_transcripts(transcriptions):\n",
    "        dfs = []\n",
    "        for n, (t, seek, connection_id) in enumerate(transcriptions):\n",
    "            df = pd.DataFrame(t)[[2, 3, 4]]\n",
    "            df.columns = ['start', 'end', 'speech']\n",
    "            df['start'] = pd.to_timedelta(df['start'], unit='s') + pd.Timestamp(seek)\n",
    "            df['end'] = pd.to_timedelta(df['end'], unit='s') + pd.Timestamp(seek)\n",
    "            df['chunk'] = n\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def prep_diarizations(diarizations):\n",
    "        dfs = []\n",
    "        for d, seek, connection_id in diarizations:\n",
    "            df = pd.DataFrame(d)\n",
    "            df['start'] = pd.to_timedelta(df['start'], unit='s') + pd.Timestamp(seek)\n",
    "            df['end'] = pd.to_timedelta(df['end'], unit='s') + pd.Timestamp(seek)\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "class DiarizationProcessor:\n",
    "    @staticmethod\n",
    "    def apply_diarization(trans_df, diar_df):\n",
    "        segments = trans_df.to_dict('records')\n",
    "        for seg in segments:\n",
    "            diar_df['intersection'] = np.minimum(diar_df['end'], seg['end']) - np.maximum(diar_df['start'], seg['start'])\n",
    "            speaker_ = diar_df[(diar_df['intersection'] == diar_df['intersection'].max()) & (diar_df['intersection'] > pd.Timedelta(0))]['speaker']\n",
    "            if len(speaker_) > 0:\n",
    "                seg['speaker'] = speaker_.iloc[0]\n",
    "        return pd.DataFrame(segments)\n",
    "\n",
    "class RedisManager:\n",
    "    def __init__(self, redis_host, redis_port, redis_password):\n",
    "        self.redis_client = None\n",
    "        self.diarization = None\n",
    "        self.transcript = None\n",
    "        self.meeting = None\n",
    "        self.redis_host = redis_host\n",
    "        self.redis_port = redis_port\n",
    "        self.redis_password = redis_password\n",
    "        self.diarizations = [] \n",
    "        self.transcriptions = []\n",
    "\n",
    "    async def initialize(self, meeting_id):\n",
    "        self.meeting_id=meeting_id\n",
    "        self.redis_client = await get_redis_client(self.redis_host, self.redis_port, self.redis_password)\n",
    "        self.diarization = Diarisation(meeting_id, redis_client=self.redis_client)\n",
    "        self.transcript = Transcript(meeting_id, redis_client=self.redis_client)\n",
    "        self.meeting = Meeting(self.redis_client, meeting_id)\n",
    "\n",
    "\n",
    "    #=========This supposed to be replaced with corresponding audio service endpoints (AKA await self.__audio_service_api.get_transcriber_segments()) ======\n",
    "    async def fetch_diarizations(self):\n",
    "        await self.load_diarizations()\n",
    "        while True:\n",
    "            d = await self.diarization.rpop()\n",
    "            if not d:\n",
    "                break\n",
    "            self.diarizations.append(json.loads(d))\n",
    "        \n",
    "        await self.store_diarizations()\n",
    "        return self.diarizations\n",
    "\n",
    "    async def fetch_transcriptions(self):\n",
    "        await self.load_transcriptions()\n",
    "        \n",
    "        while True:\n",
    "            d = await self.transcript.rpop()\n",
    "            if not d:\n",
    "                break\n",
    "            self.transcriptions.append(json.loads(d))\n",
    "            \n",
    "        await self.store_transcriptions()\n",
    "        return self.transcriptions\n",
    "    \n",
    "    #=============================above=================\n",
    "    \n",
    "    \n",
    "    async def store_diarizations(self):\n",
    "        for d in self.diarizations:\n",
    "            await self.redis_client.lpush(f\"{self.meeting_id}:diarizations\", json.dumps(d))\n",
    "    \n",
    "    async def store_transcriptions(self):\n",
    "        for t in self.transcriptions:\n",
    "            await self.redis_client.lpush(f\"{self.meeting_id}:transcriptions\", json.dumps(t))\n",
    "    \n",
    "    async def load_diarizations(self):\n",
    "        self.diarizations = []\n",
    "        while True:\n",
    "            d = await self.redis_client.rpop(f\"{self.meeting_id}:diarizations\")\n",
    "            if not d:\n",
    "                break\n",
    "            self.diarizations.append(json.loads(d))\n",
    "        return self.diarizations\n",
    "    \n",
    "    async def load_transcriptions(self):\n",
    "        self.transcriptions = []\n",
    "        while True:\n",
    "            t = await self.redis_client.rpop(f\"{self.meeting_id}:transcriptions\")\n",
    "            if not t:\n",
    "                break\n",
    "            self.transcriptions.append(json.loads(t))\n",
    "        return self.transcriptions\n",
    "    \n",
    "    async def delete(self):\n",
    "        return await self.redis_client.delete(f\"{self.meeting_id}:transcriptions\") and await self.redis_client.delete(f\"{self.meeting_id}:diarizations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "redis_manager = RedisManager(settings.redis_host, settings.redis_port, settings.redis_password)\n",
    "await redis_manager.initialize('Uc9NnN3hmWI&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await redis_manager.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trans_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     15\u001b[0m     df \u001b[38;5;241m=\u001b[39m DiarizationProcessor\u001b[38;5;241m.\u001b[39mapply_diarization(trans_df, diar_df)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m  df\u001b[38;5;241m.\u001b[39mcolumns: \n\u001b[1;32m     20\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTBD\u001b[39m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m#to be determined\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "diarizations = await redis_manager.fetch_diarizations()\n",
    "transcriptions = await redis_manager.fetch_transcriptions()\n",
    "\n",
    "trans_df = pd.DataFrame()\n",
    "diar_df = pd.DataFrame(columns = ['start','end','speaker'])\n",
    "\n",
    "if transcriptions:\n",
    "    trans_df = DataPreparation.prep_transcripts(transcriptions)\n",
    "    trans_df = trans_df[~trans_df['speech'].str.contains('|'.join(glitches))] #cleaning\n",
    "\n",
    "if diarizations:\n",
    "    diar_df = DataPreparation.prep_diarizations(diarizations)\n",
    "\n",
    "if not trans_df.empty:\n",
    "    df = DiarizationProcessor.apply_diarization(trans_df, diar_df)\n",
    "\n",
    "\n",
    "if not df.empty:\n",
    "    if 'speaker' in  df.columns: \n",
    "        df['speaker'] = df['speaker'].fillna('TBD')   #to be determined\n",
    "        rename_dict = {s: n for n, s in enumerate(df['speaker'].dropna().unique().tolist())}\n",
    "        df = df.replace(rename_dict).sort_values('start')\n",
    "        df = df.drop_duplicates('start')\n",
    "        df['change'] = df['speaker'] != df['speaker'].shift()\n",
    "        df['change'] = df['change'].cumsum()\n",
    "        df = df.groupby('change').agg({'speech': 'sum', 'speaker': 'first', 'start': 'first', 'end': 'last'}).reset_index(drop=True)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
