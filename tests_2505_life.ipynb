{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure both processes get same audio\n",
    "\n",
    "\n",
    "-choose file\n",
    "- process via diarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import timedelta\n",
    "from app.settings import settings\n",
    "from app.database_redis.connection import get_redis_client\n",
    "from app.services.audio.redis import Diarisation,Transcript\n",
    "from app.services.audio.redis import Connection, Diarizer, Meeting, Transcriber\n",
    "\n",
    "#list of common words that are strong glitch indicators that speech be removed from output\n",
    "glitches = ['DimaTorzok',' Tchau.']\n",
    "\n",
    "\n",
    "class DataPreparation:\n",
    "    @staticmethod\n",
    "    def prep_transcripts(transcriptions):\n",
    "        dfs = []\n",
    "        for n, (t, seek, connection_id) in enumerate(transcriptions):\n",
    "            df = pd.DataFrame(t)[[2, 3, 4]]\n",
    "            df.columns = ['start', 'end', 'speech']\n",
    "            df['start'] = pd.to_timedelta(df['start'], unit='s') + pd.Timestamp(seek)\n",
    "            df['end'] = pd.to_timedelta(df['end'], unit='s') + pd.Timestamp(seek)\n",
    "            df['chunk'] = n\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def prep_diarizations(diarizations):\n",
    "        dfs = []\n",
    "        for d, seek, connection_id in diarizations:\n",
    "            df = pd.DataFrame(d)\n",
    "            df['start'] = pd.to_timedelta(df['start'], unit='s') + pd.Timestamp(seek)\n",
    "            df['end'] = pd.to_timedelta(df['end'], unit='s') + pd.Timestamp(seek)\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "class DiarizationProcessor:\n",
    "    @staticmethod\n",
    "    def apply_diarization(trans_df, diar_df):\n",
    "        segments = trans_df.to_dict('records')\n",
    "        for seg in segments:\n",
    "            diar_df['intersection'] = np.minimum(diar_df['end'], seg['end']) - np.maximum(diar_df['start'], seg['start'])\n",
    "            speaker_ = diar_df[(diar_df['intersection'] == diar_df['intersection'].max()) & (diar_df['intersection'] > pd.Timedelta(0))]['speaker']\n",
    "            if len(speaker_) > 0:\n",
    "                seg['speaker'] = speaker_.iloc[0]\n",
    "        return pd.DataFrame(segments)\n",
    "\n",
    "class RedisManager:\n",
    "    def __init__(self, redis_host, redis_port, redis_password):\n",
    "        self.redis_client = None\n",
    "        self.diarization = None\n",
    "        self.transcript = None\n",
    "        self.meeting = None\n",
    "        self.redis_host = redis_host\n",
    "        self.redis_port = redis_port\n",
    "        self.redis_password = redis_password\n",
    "        self.diarizations = [] \n",
    "        self.transcriptions = []\n",
    "\n",
    "    async def initialize(self, meeting_id):\n",
    "        self.meeting_id=meeting_id\n",
    "        self.redis_client = await get_redis_client(self.redis_host, self.redis_port, self.redis_password)\n",
    "        self.diarization = Diarisation(meeting_id, redis_client=self.redis_client)\n",
    "        self.transcript = Transcript(meeting_id, redis_client=self.redis_client)\n",
    "        self.meeting = Meeting(self.redis_client, meeting_id)\n",
    "\n",
    "\n",
    "    #=========This supposed to be replaced with corresponding audio service endpoints (AKA await self.__audio_service_api.get_transcriber_segments()) ======\n",
    "    async def fetch_diarizations(self):\n",
    "        await self.load_diarizations()\n",
    "        while True:\n",
    "            d = await self.diarization.rpop()\n",
    "            if not d:\n",
    "                break\n",
    "            self.diarizations.append(json.loads(d))\n",
    "        \n",
    "        await self.store_diarizations()\n",
    "        return self.diarizations\n",
    "\n",
    "    async def fetch_transcriptions(self):\n",
    "        await self.load_transcriptions()\n",
    "        \n",
    "        while True:\n",
    "            d = await self.transcript.rpop()\n",
    "            if not d:\n",
    "                break\n",
    "            self.transcriptions.append(json.loads(d))\n",
    "            \n",
    "        await self.store_transcriptions()\n",
    "        return self.transcriptions\n",
    "    \n",
    "    #=============================above=================\n",
    "    \n",
    "    \n",
    "    async def store_diarizations(self):\n",
    "        for d in self.diarizations:\n",
    "            await self.redis_client.lpush(f\"{self.meeting_id}:diarizations\", json.dumps(d))\n",
    "    \n",
    "    async def store_transcriptions(self):\n",
    "        for t in self.transcriptions:\n",
    "            await self.redis_client.lpush(f\"{self.meeting_id}:transcriptions\", json.dumps(t))\n",
    "    \n",
    "    async def load_diarizations(self):\n",
    "        self.diarizations = []\n",
    "        while True:\n",
    "            d = await self.redis_client.rpop(f\"{self.meeting_id}:diarizations\")\n",
    "            if not d:\n",
    "                break\n",
    "            self.diarizations.append(json.loads(d))\n",
    "        return self.diarizations\n",
    "    \n",
    "    async def load_transcriptions(self):\n",
    "        self.transcriptions = []\n",
    "        while True:\n",
    "            t = await self.redis_client.rpop(f\"{self.meeting_id}:transcriptions\")\n",
    "            if not t:\n",
    "                break\n",
    "            self.transcriptions.append(json.loads(t))\n",
    "        return self.transcriptions\n",
    "    \n",
    "    async def delete(self):\n",
    "        return await self.redis_client.delete(f\"{self.meeting_id}:transcriptions\") and await self.redis_client.delete(f\"{self.meeting_id}:diarizations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "redis_manager = RedisManager(settings.redis_host, settings.redis_port, settings.redis_password)\n",
    "await redis_manager.initialize('ccn-ozkb-axo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await redis_manager.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trans_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     15\u001b[0m     df \u001b[38;5;241m=\u001b[39m DiarizationProcessor\u001b[38;5;241m.\u001b[39mapply_diarization(trans_df, diar_df)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m  df\u001b[38;5;241m.\u001b[39mcolumns: \n\u001b[1;32m     20\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTBD\u001b[39m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m#to be determined\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "diarizations = await redis_manager.fetch_diarizations()\n",
    "transcriptions = await redis_manager.fetch_transcriptions()\n",
    "\n",
    "trans_df = pd.DataFrame()\n",
    "diar_df = pd.DataFrame(columns = ['start','end','speaker'])\n",
    "\n",
    "if transcriptions:\n",
    "    trans_df = DataPreparation.prep_transcripts(transcriptions)\n",
    "    trans_df = trans_df[~trans_df['speech'].str.contains('|'.join(glitches))] #cleaning\n",
    "\n",
    "if diarizations:\n",
    "    diar_df = DataPreparation.prep_diarizations(diarizations)\n",
    "\n",
    "if not trans_df.empty:\n",
    "    df = DiarizationProcessor.apply_diarization(trans_df, diar_df)\n",
    "\n",
    "\n",
    "if not df.empty:\n",
    "    if 'speaker' in  df.columns: \n",
    "        df['speaker'] = df['speaker'].fillna('TBD')   #to be determined\n",
    "        rename_dict = {s: n for n, s in enumerate(df['speaker'].dropna().unique().tolist())}\n",
    "        df = df.replace(rename_dict).sort_values('start')\n",
    "        df = df.drop_duplicates('start')\n",
    "        df['change'] = df['speaker'] != df['speaker'].shift()\n",
    "        df['change'] = df['change'].cumsum()\n",
    "        df = df.groupby('change').agg({'speech': 'sum', 'speaker': 'first', 'start': 'first', 'end': 'last'}).reset_index(drop=True)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
