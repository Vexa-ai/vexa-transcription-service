{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Any, Union\n",
    "from uuid import uuid4\n",
    "\n",
    "import pandas as pd\n",
    "from redis.asyncio.client import Redis\n",
    "\n",
    "from app.database_redis import keys\n",
    "from app.database_redis.connection import get_redis_client\n",
    "from app.services.audio.audio import AudioFileCorruptedError, AudioSlicer\n",
    "from app.services.audio.redis import (\n",
    "    Diarisation,\n",
    "    Diarizer,\n",
    "    Meeting,\n",
    "    Transcriber,\n",
    "    Transcript,\n",
    "    best_covering_connection,\n",
    "    connection_with_minimal_start_greater_than_target,\n",
    ")\n",
    "from app.settings import settings\n",
    "\n",
    "\n",
    "def parse_segment(segment):\n",
    "    return segment[0].start, segment[0].end, int(segment[-1].split(\"_\")[1])\n",
    "\n",
    "\n",
    "async def get_next_chunk_start(diarization_result, length, shift):\n",
    "    if len(diarization_result) > 0:\n",
    "        last_speech = diarization_result[-1]\n",
    "        ended_silence = length - last_speech[\"end\"]\n",
    "        if ended_silence < 2:\n",
    "            return last_speech[\"start\"] + shift\n",
    "        else:\n",
    "            return last_speech[\"end\"] + shift\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Processor:\n",
    "    processor_type: Union[\"transcriber\", \"diarizer\"]\n",
    "    redis_client: Redis\n",
    "    logger: Any = field(default=logging.getLogger(__name__))\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.processor_type == \"transcriber\":\n",
    "            self.processor = Transcriber(self.redis_client)\n",
    "        if self.processor_type == \"diarizer\":\n",
    "            self.processor = Diarizer(self.redis_client)\n",
    "\n",
    "    async def read(self, max_length=240):\n",
    "        meeting_id = await self.processor.pop_inprogress()\n",
    "\n",
    "        if not meeting_id:\n",
    "            self.meeting = None\n",
    "            return\n",
    "\n",
    "        self.meeting = Meeting(self.redis_client, meeting_id)\n",
    "        self.logger.info(f\"Meeting ID: {meeting_id}\")\n",
    "\n",
    "        await self.meeting.load_from_redis()\n",
    "\n",
    "        if isinstance(self.processor, Diarizer):\n",
    "            self.seek_timestamp = self.meeting.diarizer_seek_timestamp\n",
    "        else:\n",
    "            self.seek_timestamp = self.meeting.transcriber_seek_timestamp\n",
    "\n",
    "        self.logger.info(f\"seek_timestamp: {self.seek_timestamp}\")\n",
    "        current_time = datetime.now(timezone.utc)\n",
    "\n",
    "        self.connections = await self.meeting.get_connections()\n",
    "        self.logger.info(f\"number of connections: {len(self.connections)}\")\n",
    "        self.connection = best_covering_connection(self.seek_timestamp, current_time, self.connections)\n",
    "\n",
    "        if self.connection:\n",
    "            self.logger.info(f\"Connection ID: {self.connection.id}\")\n",
    "\n",
    "            if self.seek_timestamp < self.connection.start_timestamp:\n",
    "                self.seek_timestamp = self.connection.start_timestamp\n",
    "\n",
    "            seek = (self.seek_timestamp - self.connection.start_timestamp).total_seconds()\n",
    "            self.logger.info(f\"seek: {seek}\")\n",
    "            path = f\"/audio/{self.connection.id}.webm\"\n",
    "\n",
    "            try:\n",
    "                audio_slicer = await AudioSlicer.from_ffmpeg_slice(path, seek, max_length)\n",
    "                self.slice_duration = audio_slicer.audio.duration_seconds\n",
    "                self.audio_data = await audio_slicer.export_data()\n",
    "                return True\n",
    "\n",
    "            except AudioFileCorruptedError:\n",
    "                self.logger.error(f\"Audio file at {path} is corrupted\")\n",
    "                await self.meeting.delete_connection(self.connection.id)\n",
    "                return\n",
    "\n",
    "            except Exception:\n",
    "                self.logger.error(f\"could nod read file {path} at seek {seek} with length {max_length}\")\n",
    "                await self.meeting.delete_connection(self.connection.id)\n",
    "                return\n",
    "\n",
    "    async def diarize(self, pipeline, qdrant_client):\n",
    "\n",
    "        output, embeddings = pipeline(io.BytesIO(self.audio_data), return_embeddings=True)\n",
    "        self.logger.info(len(embeddings))\n",
    "\n",
    "        if len(embeddings) == 0:\n",
    "            self.logger.info(\"No embeddings found, skipping...\")\n",
    "\n",
    "            self.done = False\n",
    "        else:\n",
    "            self.logger.info(f\"{len(embeddings)} embeddings found\")\n",
    "\n",
    "            segments = [i for i in output.itertracks(yield_label=True)]\n",
    "            result = pd.DataFrame([parse_segment(s) for s in segments], columns=[\"start\", \"end\", \"speaker_id\"])\n",
    "\n",
    "            diarization = Diarisation(\n",
    "                self.meeting.meeting_id,\n",
    "                self.redis_client,\n",
    "                (result, self.meeting.diarizer_seek_timestamp.isoformat(), self.connection.id),\n",
    "            )\n",
    "            await diarization.lpush()\n",
    "            self.logger.info(\"pushed\")\n",
    "\n",
    "            self.done = True\n",
    "\n",
    "    async def transcribe(self, model):\n",
    "        segments, _ = model.transcribe(\n",
    "            io.BytesIO(self.audio_data),\n",
    "            beam_size=5,\n",
    "            vad_filter=True,\n",
    "            word_timestamps=True,\n",
    "            vad_parameters={\"threshold\": 0.9},\n",
    "        )\n",
    "        segments = [s for s in list(segments)]\n",
    "        result = list(segments)\n",
    "        print(result)\n",
    "        transcription = Transcript(\n",
    "            self.meeting.meeting_id,\n",
    "            self.redis_client,\n",
    "            (result, self.meeting.transcriber_seek_timestamp.isoformat(), self.connection.id),\n",
    "        )\n",
    "        if len(result) > 0:\n",
    "            await transcription.lpush()\n",
    "            self.logger.info(\"pushed\")\n",
    "            self.done = True\n",
    "\n",
    "        else:\n",
    "            self.done = False\n",
    "\n",
    "    async def find_next_seek(self, overlap=0):\n",
    "        if self.done:\n",
    "            self.seek_timestamp = (\n",
    "                self.seek_timestamp + pd.Timedelta(seconds=self.slice_duration) - pd.Timedelta(seconds=overlap)\n",
    "            )\n",
    "        else:\n",
    "            next_connection = connection_with_minimal_start_greater_than_target(self.seek_timestamp, self.connections)\n",
    "            if next_connection:\n",
    "                self.seek_timestamp = next_connection.start_timestamp\n",
    "        self.logger.info(f\"seek_timestamp: {self.seek_timestamp}\")\n",
    "\n",
    "        if isinstance(self.processor, Diarizer):\n",
    "            self.meeting.diarizer_seek_timestamp = self.seek_timestamp\n",
    "        else:\n",
    "            self.meeting.transcriber_seek_timestamp = self.seek_timestamp\n",
    "\n",
    "        await self.meeting.update_redis()\n",
    "\n",
    "    async def do_finally(self):\n",
    "        if self.meeting:\n",
    "            await self.processor.remove(self.meeting.meeting_id)\n",
    "            await self.meeting.update_redis()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
