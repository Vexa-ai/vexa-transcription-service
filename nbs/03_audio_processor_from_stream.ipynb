{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/app')\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from audio.redis import *\n",
    "from audio.audio import *\n",
    "#from audio.process import *\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import asyncio\n",
    "import redis.asyncio as aioredis\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = '851f343e-4954-4f0a-8835-9664cc91c181'\n",
    "import subprocess\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "from time import sleep\n",
    "\n",
    "from audio.redis import Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_inner_client = await get_inner_redis()\n",
    "redis_stream_client = await get_stream_redis()\n",
    "client_id = '851f343e-4954-4f0a-8835-9664cc91c181'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_next_chunk_start(diarization_result, length):\n",
    "    if len(diarization_result)>0:\n",
    "        last_speech = diarization_result[-1]\n",
    "\n",
    "        ended_silence = length - last_speech['end']\n",
    "        print(ended_silence)\n",
    "        if ended_silence<1:\n",
    "            print('interrupted')\n",
    "            return last_speech['conv_start']\n",
    "        \n",
    "\n",
    "        else:\n",
    "            print('non-interrupted') \n",
    "            return last_speech['conv_end']\n",
    "\n",
    "\n",
    "\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def diarize(client_id, audio_name, shift):\n",
    "    await redis_inner_client.lpush('Audio2DiarizeQueue', f'{audio_name}:{client_id}')\n",
    "    done = await redis_inner_client.brpop(f'DiarizeReady:{audio_name}')\n",
    "    diarization = Diarisation(audio_name, redis_inner_client)\n",
    "    await diarization.get()\n",
    "    df = pd.DataFrame(diarization.data)\n",
    "    df['len'] = df['end'] - df['start']\n",
    "\n",
    "    if len(df)>0:\n",
    "        expanded_df = pd.DataFrame(columns=['speaker', 'time'])\n",
    "        for index, row in df.iterrows():\n",
    "            time_range = np.arange(row['start'] * 100, row['end'] * 100, 1).astype(int)\n",
    "\n",
    "            temp_df = pd.DataFrame({\n",
    "                'speaker': row['speaker'],\n",
    "                'time': time_range\n",
    "            })\n",
    "            expanded_df = pd.concat([expanded_df, temp_df], ignore_index=True)\n",
    "        expanded_df['time'] = (expanded_df['time'] / 100.0).astype('float')\n",
    "        expanded_df['conv_time'] = (expanded_df['time'] + shift).astype('float')\n",
    "\n",
    "        return expanded_df.sort_values(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def transcribe(audio_name):\n",
    "    await redis_inner_client.lpush('Audio2TranscribeQueue', f'{audio_name}:{client_id}')\n",
    "    _,done = await redis_inner_client.brpop(f'TranscribeReady:{audio_name}')\n",
    "    transcription =  Transcript(audio_name,redis_inner_client)\n",
    "    await transcription.get()\n",
    "    df =  pd.concat([pd.DataFrame(t) for t in transcription.data])\n",
    "\n",
    "\n",
    "    df['start'] = df['start'].astype('float')\n",
    "    return df.sort_values(\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queue</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>initialFeed_audio:cfee46c2-db72-472a-bdd1-1de4...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>initialFeed_audio:ed67050b-656f-4977-807b-8293...</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               queue  length\n",
       "0  initialFeed_audio:cfee46c2-db72-472a-bdd1-1de4...       3\n",
       "1  initialFeed_audio:ed67050b-656f-4977-807b-8293...     648"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await get_connections_df('initialFeed_audio',redis_stream_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections =  await get_connections('initialFeed_audio',redis_stream_client)\n",
    "connection_ids = [c.replace('initialFeed_audio:','') for c in connections]\n",
    "\n",
    "\n",
    "connections =  await get_connections('initialFeed_audio',redis_stream_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[await redis_stream_client.delete(c) for c in connections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_id = 'david_audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = f'/app/testdata/{connection_id}.webm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_start = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#on_start = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2000\n",
    "length = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.048\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "async def process():\n",
    "    await writestream2file(connection_id,redis_stream_client)\n",
    "    print(start)\n",
    "    if on_start:  audio_slicer = await AudioSlicer.from_file(path,format = 'webm')\n",
    "    else       :  audio_slicer = await AudioSlicer.from_ffmpeg_slice(path,start,length)\n",
    "\n",
    "    slice_duration = audio_slicer.audio.duration_seconds\n",
    "    print(slice_duration)\n",
    "\n",
    "    if slice_duration > length:\n",
    "\n",
    "        audio_data = await audio_slicer.export_data()\n",
    "        audio_name = str(uuid.uuid4())\n",
    "        audio = Audio(chunk_name=audio_name, redis_client=redis_inner_client, data=audio_data)\n",
    "        await audio.save()\n",
    "\n",
    "    diarization_result = await diarize(client_id,audio_name,start)\n",
    "\n",
    "    transcription_result = await transcribe(audio_name)\n",
    "    df = pd.merge_asof(transcription_result,diarization_result,left_on = 'start',right_on='time',direction='nearest')\n",
    "    df['speaker_change'] = df['speaker'] != df['speaker'].shift()\n",
    "    df['silence'] = df['start']-df['end'].shift()\n",
    "\n",
    "    df['speaker_change'] = np.where(df['silence']>2,True,df['speaker_change'])\n",
    "\n",
    "\n",
    "    df['speaker_change'] = df['speaker_change'].cumsum()\n",
    "    df = df.groupby('speaker_change').agg({'speaker': 'first', 'start': 'first', 'end': 'last'}).join(df.groupby('speaker_change').apply(lambda x:''.join(x['word'])).to_frame('text'))\n",
    "    df['len'] = df['end'] - df['start']\n",
    "    df['speaker'] = np.where(df['len']>0.5,df['speaker'],np.nan)\n",
    "    df['speaker'] = df['speaker'].fillna(method='ffill').fillna(method='bfill')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
