# Real-Time Audio Transcription Service

A **production-ready, scalable** real-time audio transcription system designed for **enterprise and SaaS applications**. This system powers **secure, private, and highly accurate speech-to-text conversion**, serving as the **backbone for Vexa.ai**, an **alternative to Otter.ai, Fireflies.ai, and Tactiq.io**, enabling enterprises to build custom AI-powered conversation processing solutions.

> **ğŸ”’ Enterprise-Grade Security & Compliance** Unlike cloud-based transcription services, this system allows for full **on-premise deployment**, ensuring that all transcription data remains within your organization's infrastructure. Ideal for **high-security environments**.

## ğŸš€ Why Choose This Transcription System?

### **Enterprise-First Approach**

âœ” **Multiuser Production-Ready** â€“ Built for **enterprise-scale** deployment âœ” **Data Sovereignty** â€“ Your audio and text **never leave your network** âœ” **GDPR & HIPAA Compliance** â€“ Meet strict data privacy regulations âœ” **Custom Security Policies** â€“ Integrate with your **existing authentication** & access controls âœ” **Air-Gapped Deployment** â€“ Works in **offline environments** âœ” **Enterprise Scalability** â€“ Designed for large workloads, supporting 1000s of concurrent users

### **Core Capabilities**

âœ… **Real-time transcription** with speaker detection\
âœ… **Multi-platform support** â€“ **Google Meet Chrome Extension available**, future integrations for Zoom, Microsoft Teams, Slack, etc.\
âœ… **Bring Your Own Data Source** â€“ Flexible API allows integration with **custom platforms**\
âœ… **5-10 second transcription latency** for seamless live captions\
âœ… **Redis-backed storage** for fast retrieval & webhook-based integrations\
âœ… **Whisper v3 (optimized) for high-accuracy speech-to-text**\
âœ… **GPU acceleration** for ultra-fast processing

---

## ğŸ¢ **Who Should Use This?**

We are actively looking for **enterprises and SaaS teams** currently using services like **Otter.ai, Fireflies.ai, and Tactiq.io**, but need **better privacy, control, and customization**.

ğŸ”¹ **Enterprise Meeting Transcription** â€“ Automate meeting notes with speaker attribution\
ğŸ”¹ **Customer Support & Call Centers** â€“ Real-time call transcription & agent assistance\
ğŸ”¹ **Education & Accessibility** â€“ Create searchable lecture transcripts & captions\
ğŸ”¹ **Content Creation** â€“ Transcribe podcasts, generate subtitles, and repurpose audio content\
ğŸ”¹ **Medical & Healthcare** â€“ Secure, HIPAA-compliant transcription for patient records\
ğŸ”¹ **Sales & CRM** â€“ Capture and analyze sales calls for insights and training\
ğŸ”¹ **Internal Management Meetings** â€“ Automate documentation of leadership discussions\
ğŸ”¹ **Legal & Compliance** â€“ Generate accurate transcripts for legal proceedings and documentation

---

## âš™ï¸ System Architecture

The pipeline consists of **scalable microservices** designed for **high-volume real-time transcription**:

### **1ï¸âƒ£ StreamQueue API** â€“ Handles reliable audio ingestion

- Ensures delivery of **audio chunks every 3 seconds**
- Supports **multiple concurrent sessions**

### **2ï¸âƒ£ Audio Processing Service** â€“ Core audio transcription engine

- Calls **Whisper Service** for speech-to-text processing
- Stores transcriptions **with speaker metadata** in Redis
- Supports **webhook integrations** for real-time updates

### **3ï¸âƒ£ Whisper Service** â€“ GPU-powered transcription module

- Runs **Whisper large-v3** model for **best accuracy**
- Deployed with **Ray Serve** for **scalability & efficiency**

### **4ï¸âƒ£ Redis Storage** â€“ Fast, ephemeral transcript storage

- Enables **quick retrieval & session-based storage**
- Serves as a **message broker** between services

---

## ğŸ›  **Quick Start**

### **1. Clone the Repositories**

```sh
# Clone the audio processing service
git clone https://github.com/yourusername/audio.git

# Clone the whisper service
git clone https://github.com/yourusername/whisper_service.git
```

### **2. Configure the Environment**

```sh
# Set up environment variables for audio service
cd audio
cp .env.example .env

# Set up environment variables for whisper service
cd ../whisper_service
cp .env.example .env
```

Edit `.env` files to configure **API tokens, GPU settings, and webhooks**.

### **3. Start the Whisper Service** (GPU Required)

```sh
cd whisper_service
docker-compose up -d
```

### **4. Start the Audio Service**

```sh
cd ../audio
docker-compose up -d
```

---

## ğŸ”Œ **Integration Guide**

### **1ï¸âƒ£ Sending Audio Chunks** (Example in JavaScript)

```js
async function sendAudioChunk(audioBlob, sessionId) {
  await fetch('http://your-server:8000/api/audio/stream', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer your_api_token',
      'Content-Type': 'application/octet-stream',
      'X-Session-ID': sessionId
    },
    body: audioBlob
  });
}
```

### **2ï¸âƒ£ Updating Speaker Info**

```js
async function updateSpeaker(sessionId, speakerName) {
  await fetch('http://your-server:8000/api/speaker', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer your_api_token',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ session_id: sessionId, speaker_name: speakerName })
  });
}
```

### **3ï¸âƒ£ Receiving Transcriptions via Webhook**

```python
from fastapi import FastAPI, Body
from pydantic import BaseModel
from typing import List, Dict

app = FastAPI()

class TranscriptionSegment(BaseModel):
    content: str
    start_timestamp: str
    end_timestamp: str
    speaker: str = None
    words: List[Dict] = []

@app.post("/api/transcriptions/{session_id}")
async def receive_transcription(session_id: str, segments: List[TranscriptionSegment] = Body(...)):
    print("Transcription received:", segments)
    return {"status": "success"}
```

---

## ğŸ¤ **How to Contribute**

We welcome **contributions from enterprises and developers**! If your company is migrating from **Otter.ai, Fireflies, or Tactiq**, weâ€™d love to hear your use case.

### **Ways to Contribute**

\
âœ… **Optimize latency & scaling** for enterprise workloads\
âœ… **Enhance security & compliance features**\
âœ… **Integrate with CRM, customer support tools, and knowledge bases**\
âœ… **Integrate with Zoom and Microsoft Teams for seamless transcription**

ğŸš€ **Join the open-source effort today!** Submit a **Pull Request**, open a **GitHub Issue**, or **contact us**.

---

## ğŸ”— **Related Projects**

This project is a core component of **[Vexa](https://vexa.ai)** â€“ an **AI-powered meeting intelligence** platform that extends transcription into **business knowledge extraction**.

ğŸ”¹ Try Vexa for **real-time transcription & AI-driven insights**: [vexa.ai](https://vexa.ai)\
ğŸ”¹ Follow us: [@vexa.ai](https://linkedin.com/company/vexa-ai)\
ğŸ”¹ Join our **developer community**: [Vexa Discord](https://discord.gg/vexa)

â­ **Star this repo** to get notified when the public release goes live!

